{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner: Natural Language Processor\n",
    "\n",
    "## 1. Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lowercase\n",
    "text = text.lower()\n",
    "\n",
    "#Dealing with numbers \n",
    "text = ''.join(word for word in text if not word.isdigit()) #get rid of the number in text\n",
    "\n",
    "#dealing with punctuation\n",
    "import string \n",
    "for punctuation in string.punctuation:\n",
    "    text = text.replace(punctuation, '') \n",
    "\n",
    "#Removing \"stopwords\"\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "word_tokens = word_tokenize(text) \n",
    "  \n",
    "text = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "#Tokenizing\n",
    "\n",
    "\n",
    "#Stemming or Lemmatizing\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "stemmed = [stemmer.stem(word) for word in text]\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __Tf-idf__<br>\n",
    "disadvantage: does not capture context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>football</th>\n",
       "      <th>game</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.444514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   football      game        is      love\n",
       "0  0.613356  0.000000  0.000000  0.789807\n",
       "1  0.345205  0.584483  0.584483  0.444514\n",
       "2  1.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "texts = ['i love football',\n",
    "         'football is a game i love',\n",
    "        'football football football']\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> key params\n",
    "> 1. __max_df__: Used to exclude \"corpus specific stopwords\", words that are very frequent in the dataset. The vectorizer will ignore the words that have a frequency higher than the specified threshold.\n",
    "> 2. __min_df__: Used to exclude words that are very infrequent in the dataset. The vectorizer will ignore the words that have a frequency lower than the specified threshold.\n",
    "> 3. __max_features__:Used to specify the number of features to keep when vectorizing. It will retain the top features according to count or tf-idf score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.47363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       game        is     love\n",
       "0  0.000000  0.000000  1.00000\n",
       "1  0.622766  0.622766  0.47363\n",
       "2  0.000000  0.000000  0.00000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(max_df = 0.8)\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>football</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   football      love\n",
       "0  0.613356  0.789807\n",
       "1  0.613356  0.789807\n",
       "2  1.000000  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(min_df = 0.5)\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>football</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.613356</td>\n",
       "      <td>0.789807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   football      love\n",
       "0  0.613356  0.789807\n",
       "1  0.613356  0.789807\n",
       "2  1.000000  0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(max_features = 2)\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Capturing Context: __N-Gram representation__\n",
    "> - N is the number of words to be consiered as a one.\n",
    "> - __ngram_range__: A parameter of the two vectorizers to specify the length of sequences to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =  ['i do not love football',\n",
    "         'i love football not basketball']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>do not</th>\n",
       "      <th>football not</th>\n",
       "      <th>love football</th>\n",
       "      <th>not basketball</th>\n",
       "      <th>not love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.449436</td>\n",
       "      <td>0.631667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     do not  football not  love football  not basketball  not love\n",
       "0  0.631667      0.000000       0.449436        0.000000  0.631667\n",
       "1  0.000000      0.631667       0.449436        0.631667  0.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(ngram_range = (2,2))\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(texts)\n",
    "\n",
    "X.toarray()\n",
    "\n",
    "pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering\n",
    "> Sometimes, you may want to extract your own features from the texts. Some common features are: <br>\n",
    ">- Vocabulary Richness<br>\n",
    ">- Average word per line<br>\n",
    ">- Digit/Character ratio<br>\n",
    ">- Anything you can think of that relates to the task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_richness(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    total_length = len(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    unique_word_length = len(unique_words)\n",
    "    return unique_word_length/total_length\n",
    "\n",
    "data['vocab richness'] = data.text.apply(vocab_richness)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.(Multinomia) Naive Bayers Algorithm\n",
    "> disadvantages:\n",
    "> - Assumes feature independence, rarely the case in real life datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(data.text)\n",
    "y = data['spam']\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "nb_model.fit(X,y)\n",
    "\n",
    "nb_model.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Pipeling and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1), (2,2)),\n",
    "    'nb__alpha': (0.1,1),}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "grid_search.fit(data.text,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Latent Dirichlet Allocation\n",
    "> Latent Dirichlet Allocation is an unsupervised learning algorithm for text data. It is based on co-occurences of words in texts and is used to find topics from a corpus of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "vectorizer = TfidfVectorizer().fit(data['text'])\n",
    "\n",
    "data_vectorized = vectorizer.transform(data['text'])\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_components=2).fit(data_vectorized)\n",
    "\n",
    "def print_topics(model, vectorizer):\n",
    "    for idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic %d:\" % (idx))\n",
    "        print([(vectorizer.get_feature_names()[i], topic[i])\n",
    "                        for i in topic.argsort()[:-10 - 1:-1]])\n",
    "        \n",
    "\n",
    "print_topics(lda_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = [\"rice var congratulations save upenn\"]\n",
    "\n",
    "example_vectorized = vectorizer.transform(example)\n",
    "\n",
    "lda_vectors = lda_model.transform(example_vectorized)\n",
    "\n",
    "print(\"topic 0 :\", lda_vectors[0][0])\n",
    "print(\"topic 1 :\", lda_vectors[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with RNN\n",
    "> __language model__: A language model is a model which attempts to predict the next word or character given an input list of words or characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

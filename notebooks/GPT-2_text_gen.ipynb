{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simpletransformers.language_modeling import LanguageModelingModel\n",
    "from simpletransformers.language_generation import LanguageGenerationModel\n",
    "import warnings\n",
    "import pickle\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(post):\n",
    "    post_split = post.split('|||')\n",
    "    # split the kaggle data set posts by |||\n",
    "    post_split_split = [x.split(' ') for x in post_split]\n",
    "    \n",
    "    # removes any 'words' that have http:// or https:// in them\n",
    "    return_list = [[item for item in sentence if ('http://' not in item and 'https://' not in item)] for sentence in post_split_split]\n",
    "    \n",
    "    # returns a list of posts if they are not empty after removing the links\n",
    "    return [' '.join(sentence) for sentence in return_list if sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'INTJ':0, 'INTP':0, 'ENTJ':1, 'ENTP':1, \n",
    "           'INFJ':0, 'INFP':0, 'ENFJ':1, 'ENFP':1, \n",
    "           'ISTJ':0, 'ISFJ':0, 'ESTJ':1, 'ESFJ':1, \n",
    "           'ISTP':0, 'ISFP':0, 'ESTP':1, 'ESFP':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTJ (200, 2)\n",
      "INTP (200, 2)\n",
      "ENTJ (200, 2)\n",
      "ENTP (200, 2)\n",
      "INFJ (200, 2)\n",
      "INFP (200, 2)\n",
      "ENFJ (190, 2)\n",
      "ENFP (200, 2)\n",
      "ISTJ (200, 2)\n",
      "ISFJ (166, 2)\n",
      "ESTJ (39, 2)\n",
      "ESFJ (42, 2)\n",
      "ISTP (200, 2)\n",
      "ISFP (200, 2)\n",
      "ESTP (89, 2)\n",
      "ESFP (48, 2)\n"
     ]
    }
   ],
   "source": [
    "for dataframe in df_dict.keys():\n",
    "    if(df[df['type'] == dataframe].shape[0] < 200):\n",
    "        df_dict[dataframe] = df[df['type'] == dataframe]\n",
    "    else:\n",
    "        df_dict[dataframe] = df[df['type'] == dataframe].sample(n=200)\n",
    "    df_dict[dataframe]['post_split'] = df_dict[dataframe].posts.apply(clean)\n",
    "    print(dataframe, df_dict[dataframe].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>post_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Hi, are you really manic?|||greetings.|||Yes,...</td>\n",
       "      <td>['Hi, are you really manic?, greetings., Yes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>This is good...I was asking for a group analys...</td>\n",
       "      <td>[This is good...I was asking for a group analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'throughtheroses  I cannot help you with this,...</td>\n",
       "      <td>['throughtheroses  I cannot help you with this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I got 23|||YAYYYY!! XD Can I have a cookie in...</td>\n",
       "      <td>['I got 23, YAYYYY!! XD Can I have a cookie in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6810</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Psychology is a science. You probably feel un...</td>\n",
       "      <td>['Psychology is a science. You probably feel u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "167   INTJ  'Hi, are you really manic?|||greetings.|||Yes,...   \n",
       "7500  INTJ  This is good...I was asking for a group analys...   \n",
       "790   INTJ  'throughtheroses  I cannot help you with this,...   \n",
       "4514  INTJ  'I got 23|||YAYYYY!! XD Can I have a cookie in...   \n",
       "6810  INTJ  'Psychology is a science. You probably feel un...   \n",
       "\n",
       "                                             post_split  \n",
       "167   ['Hi, are you really manic?, greetings., Yes, ...  \n",
       "7500  [This is good...I was asking for a group analy...  \n",
       "790   ['throughtheroses  I cannot help you with this...  \n",
       "4514  ['I got 23, YAYYYY!! XD Can I have a cookie in...  \n",
       "6810  ['Psychology is a science. You probably feel u...  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['INTJ'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in df_dict.keys():\n",
    "    df_dict[dataframe] = df_dict[dataframe].post_split.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_posts_to_file(posts, file):\n",
    "    for post in posts:\n",
    "        for ind_post in post:\n",
    "            if(re.search('[a-zA-Z]', ind_post)):\n",
    "                if(ind_post.endswith('...')or ind_post.endswith(\"...'\")):\n",
    "                    if(re.search('.*[\\.?!]\\s', ind_post)):\n",
    "                        file.writelines(re.search('.*[\\.?!]\\s', ind_post).group(0).strip() + \"\\n\")\n",
    "                else:\n",
    "                    file.writelines(ind_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_ in df_dict.keys():\n",
    "    with open(f\"../data/2.0_GPT-2_text_gen_posts/{type_}_posts_train.txt\", \"w\") as f:\n",
    "        write_posts_to_file(df_dict[type_][:-15], f)\n",
    "\n",
    "    with open(f\"../data/2.0_GPT-2_text_gen_posts/{type_}_posts_test.txt\", \"w\") as f:\n",
    "        write_posts_to_file(df_dict[type_][-15:], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"mlm\": False,\n",
    "}\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d3faa8851842698b743f30cb2a366b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1572.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a1cc544fdb4ef88998ea8b264232d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=720.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf0f5a93df34adc9a752a49d2600a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af512f9bbc874814b1b8b4ab7e2e4af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Running Epoch 0 of 3'), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7510dc8c0d42ca986ad30c198c916d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Running Epoch 1 of 3'), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3a149950dd48acb0872049d403767c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Running Epoch 2 of 3'), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(36, 4.239758994844225)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_ = 'ESTP'\n",
    "model = LanguageModelingModel('gpt2', 'gpt2', args=train_args, use_cuda=False)\n",
    "\n",
    "model.train_model(train_file = f\"../data/2.0_GPT-2_text_gen_posts/{type_}_posts_train.txt\", \n",
    "                  eval_file = f\"../data/2.0_GPT-2_text_gen_posts/{type_}_posts_test.txt\", \n",
    "                  output_dir = f\"2.0_gen_lang_models/{type_}_lang_model/\")\n",
    "\n",
    "# pickle.dump(model, open(f'models/{type_}_lang_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7df76d24df04a5b842237654f1311c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=260.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eaeee54b3f649e18bce4ca3a06fba84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=142.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2eeddb11b240d3a991d8a18494d9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Running Evaluation'), FloatProgress(value=0.0, max=18.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results.append((type_, model.eval_model(f\"../data/2.0_GPT-2_text_gen_posts/{type_}_posts_test.txt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ESFP', {'eval_loss': 4.146227061748505, 'perplexity': tensor(63.1951)}),\n",
       " ('ESTP', {'eval_loss': 4.114682740635342, 'perplexity': tensor(61.2328)})]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = LanguageGenerationModel(\"gpt2\", f\"2.0_gen_lang_models/{type_}_lang_model/\", args={\"max_length\": 16}, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"I was always bullied by my family for being small, \\\n",
    "I think they were always jealous of how much smarter I was compared to them. \\\n",
    "I never let it bother me, because I knew in the end I would be more successful than any of them.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    # Generate text using the model. Verbose set to False to prevent logging generated sequences.\n",
    "    generated = ''\n",
    "    while len(generated) <= len(prompt):\n",
    "        generated = gen_model.generate(prompt, verbose=False, args={\"max_length\": 5})\n",
    "        generated = '.'.join(generated[0].split('.')[:-1]) + '.'\n",
    "    print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from simpletransformers.language_modeling import LanguageModelingModel\n",
    "from simpletransformers.language_generation import LanguageGenerationModel\n",
    "import warnings\n",
    "import pickle\n",
    "import re\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(post):\n",
    "    post_split = post.split('|||')\n",
    "    # split the kaggle data set posts by |||\n",
    "    post_split_split = [x.split(' ') for x in post_split]\n",
    "    \n",
    "    # removes any 'words' that have http:// or https:// in them\n",
    "    return_list = [[item for item in sentence if ('http://' not in item and 'https://' not in item)] for sentence in post_split_split]\n",
    "    \n",
    "    # returns a list of posts if they are not empty after removing the links\n",
    "    return [' '.join(sentence) for sentence in return_list if sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'INTJ':0, 'INTP':0, 'ENTJ':1, 'ENTP':1, \n",
    "           'INFJ':0, 'INFP':0, 'ENFJ':1, 'ENFP':1, \n",
    "           'ISTJ':0, 'ISFJ':0, 'ESTJ':1, 'ESFJ':1, \n",
    "           'ISTP':0, 'ISFP':0, 'ESTP':1, 'ESFP':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTJ (1091, 2)\n",
      "INTP (1304, 2)\n",
      "ENTJ (231, 2)\n",
      "ENTP (685, 2)\n",
      "INFJ (1470, 2)\n",
      "INFP (1832, 2)\n",
      "ENFJ (190, 2)\n",
      "ENFP (675, 2)\n",
      "ISTJ (205, 2)\n",
      "ISFJ (166, 2)\n",
      "ESTJ (39, 2)\n",
      "ESFJ (42, 2)\n",
      "ISTP (337, 2)\n",
      "ISFP (271, 2)\n",
      "ESTP (89, 2)\n",
      "ESFP (48, 2)\n"
     ]
    }
   ],
   "source": [
    "for dataframe in df_dict.keys():\n",
    "    df_dict[dataframe] = df[df['type'] == dataframe]\n",
    "    print(dataframe, df_dict[dataframe].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTJ (1091, 3)\n",
      "INTP (1304, 3)\n",
      "ENTJ (231, 3)\n",
      "ENTP (685, 3)\n",
      "INFJ (1470, 3)\n",
      "INFP (1832, 3)\n",
      "ENFJ (190, 3)\n",
      "ENFP (675, 3)\n",
      "ISTJ (205, 3)\n",
      "ISFJ (166, 3)\n",
      "ESTJ (39, 3)\n",
      "ESFJ (42, 3)\n",
      "ISTP (337, 3)\n",
      "ISFP (271, 3)\n",
      "ESTP (89, 3)\n",
      "ESFP (48, 3)\n"
     ]
    }
   ],
   "source": [
    "for dataframe in df_dict.keys():\n",
    "    df_dict[dataframe]['post_split'] = df_dict[dataframe].posts.apply(clean)\n",
    "    print(dataframe, df_dict[dataframe].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>post_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>['Dear INTP,   I enjoyed our conversation the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'18/37 @.@|||Science  is not perfect. No scien...</td>\n",
       "      <td>['18/37 @.@, Science  is not perfect. No scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I tend to build up a collection of things on ...</td>\n",
       "      <td>['I tend to build up a collection of things on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Fair enough, if that's how you want to look a...</td>\n",
       "      <td>['Fair enough, if that's how you want to look ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Poker face for sure, accompanied by some sarc...</td>\n",
       "      <td>['Poker face for sure, accompanied by some sar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                                              posts  \\\n",
       "3   INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "5   INTJ  '18/37 @.@|||Science  is not perfect. No scien...   \n",
       "7   INTJ  'I tend to build up a collection of things on ...   \n",
       "13  INTJ  'Fair enough, if that's how you want to look a...   \n",
       "36  INTJ  'Poker face for sure, accompanied by some sarc...   \n",
       "\n",
       "                                           post_split  \n",
       "3   ['Dear INTP,   I enjoyed our conversation the ...  \n",
       "5   ['18/37 @.@, Science  is not perfect. No scien...  \n",
       "7   ['I tend to build up a collection of things on...  \n",
       "13  ['Fair enough, if that's how you want to look ...  \n",
       "36  ['Poker face for sure, accompanied by some sar...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict['INTJ'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataframe in df_dict.keys():\n",
    "    df_dict[dataframe] = df_dict[dataframe].post_split.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_ in df_dict.keys():\n",
    "    with open(f\"../data/GPT-2_text_gen_posts/{type_}_posts_train.txt\", \"w\") as f:\n",
    "        for post in df_dict[type_][:-10]:\n",
    "            for ind_post in post:\n",
    "                if(re.search('[a-zA-Z]', ind_post)):\n",
    "                    f.writelines(ind_post + \"\\n\")\n",
    "\n",
    "    with open(f\"../data/GPT-2_text_gen_posts/{type_}_posts_test.txt\", \"w\") as f:\n",
    "        for post in df_dict[type_][-10:]:\n",
    "            for ind_post in post:\n",
    "                if(re.search('[a-zA-Z]', ind_post)):\n",
    "                    f.writelines(ind_post + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"train_batch_size\": 64,\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"mlm\": False,\n",
    "}\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_ = 'ESTP'\n",
    "model = LanguageModelingModel('gpt2', 'gpt2', args=train_args, use_cuda=False)\n",
    "\n",
    "model.train_model(train_file = f\"../data/GPT-2_text_gen_posts/{type_}_posts_train.txt\", \n",
    "                  eval_file = f\"../data/GPT-2_text_gen_posts/{type_}_posts_test.txt\", \n",
    "                  output_dir = f\"gen_lang_models/{type_}_lang_model/\")\n",
    "\n",
    "# pickle.dump(model, open(f'models/{type_}_lang_model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1803259434c2417d9382dbd7f459e2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=436.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6394bd7760a14c0b85b03fed1ab4761b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=115.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c7b9df3221a4aac80113a931b461739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Running Evaluation'), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results.append((type_, model.eval_model(f\"../data/GPT-2_text_gen_posts/{type_}_posts_test.txt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = LanguageGenerationModel(\"gpt2\", \"gen_lang_models/ESFP_lang_model/\", args={\"max_length\": 64}, use_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    'Hello, my name is',\n",
    "    'I really do not',\n",
    "    'My favorite thing to do',\n",
    "    'I really like',\n",
    "    \"I hope you don't\",\n",
    "    'You are the very reason why'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is David Prowse. I'm a student in your high school biology department. I just found out that I'm the mother of my children.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really do not like to be accused by friends or any group, I think it's like an unneeded exclamation point to have the guy you date take it too seriously.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My favorite thing to do when I first go to my apartment is to take a walk to talk to you about what to do for a job.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really like the sound of the voice. It sounds really strong so I'm always happy to hear a person's voice.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "    # Generate text using the model. Verbose set to False to prevent logging generated sequences.\n",
    "    generated = gen_model.generate(prompt, verbose=False, args={\"max_length\": 32})\n",
    "\n",
    "    generated = '.'.join(generated[0].split('.')[:-1]) + '.'\n",
    "    print(generated)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

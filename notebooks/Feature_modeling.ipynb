{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/kaggle_data_scaled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = 'Unnamed: 0',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_per_sentence'] = df['word_count']/df['sentence_count']\n",
    "df['avg_word_length'] = df['word_length']/df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>sentence_count</th>\n",
       "      <th>syll_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_per_sentence</th>\n",
       "      <th>word_length</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>count_unique_word</th>\n",
       "      <th>TTR</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>...</th>\n",
       "      <th>disgust</th>\n",
       "      <th>joy</th>\n",
       "      <th>syll_count_scaled</th>\n",
       "      <th>word_count_scaled</th>\n",
       "      <th>count_unique_word_scaled</th>\n",
       "      <th>word_length_scaled</th>\n",
       "      <th>sentence_count_scaled</th>\n",
       "      <th>TTR_scaled</th>\n",
       "      <th>avg_word_length_scaled</th>\n",
       "      <th>word_per_sentence_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>24</td>\n",
       "      <td>870</td>\n",
       "      <td>579</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>3154</td>\n",
       "      <td>5.447323</td>\n",
       "      <td>370</td>\n",
       "      <td>0.639033</td>\n",
       "      <td>0.075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.139860</td>\n",
       "      <td>-1.639844</td>\n",
       "      <td>-1.694270</td>\n",
       "      <td>-1.295213</td>\n",
       "      <td>-1.670848</td>\n",
       "      <td>-3.428571</td>\n",
       "      <td>0.764467</td>\n",
       "      <td>0.986176</td>\n",
       "      <td>0.494162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>41</td>\n",
       "      <td>1700</td>\n",
       "      <td>1252</td>\n",
       "      <td>30.536585</td>\n",
       "      <td>6266</td>\n",
       "      <td>5.004792</td>\n",
       "      <td>607</td>\n",
       "      <td>0.484824</td>\n",
       "      <td>0.086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031414</td>\n",
       "      <td>0.094241</td>\n",
       "      <td>-0.196164</td>\n",
       "      <td>-0.023770</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>-0.173952</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.888211</td>\n",
       "      <td>7.318157</td>\n",
       "      <td>0.023770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>42</td>\n",
       "      <td>1326</td>\n",
       "      <td>895</td>\n",
       "      <td>21.309524</td>\n",
       "      <td>4879</td>\n",
       "      <td>5.451397</td>\n",
       "      <td>525</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065990</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>-0.846690</td>\n",
       "      <td>-0.909904</td>\n",
       "      <td>-0.434325</td>\n",
       "      <td>-0.841110</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>0.477330</td>\n",
       "      <td>0.924393</td>\n",
       "      <td>1.061555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>48</td>\n",
       "      <td>1699</td>\n",
       "      <td>1160</td>\n",
       "      <td>24.166667</td>\n",
       "      <td>6028</td>\n",
       "      <td>5.196552</td>\n",
       "      <td>591</td>\n",
       "      <td>0.509483</td>\n",
       "      <td>0.053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.081395</td>\n",
       "      <td>-0.197903</td>\n",
       "      <td>-0.252130</td>\n",
       "      <td>-0.067753</td>\n",
       "      <td>-0.288432</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268724</td>\n",
       "      <td>1.143983</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>42</td>\n",
       "      <td>1509</td>\n",
       "      <td>1035</td>\n",
       "      <td>24.642857</td>\n",
       "      <td>5539</td>\n",
       "      <td>5.351691</td>\n",
       "      <td>545</td>\n",
       "      <td>0.526570</td>\n",
       "      <td>0.127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057778</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>-0.528384</td>\n",
       "      <td>-0.562401</td>\n",
       "      <td>-0.323243</td>\n",
       "      <td>-0.523645</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>0.574755</td>\n",
       "      <td>0.931088</td>\n",
       "      <td>0.656134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9093</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>15</td>\n",
       "      <td>332</td>\n",
       "      <td>183</td>\n",
       "      <td>12.200000</td>\n",
       "      <td>1105</td>\n",
       "      <td>6.038251</td>\n",
       "      <td>15</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.575627</td>\n",
       "      <td>-2.677209</td>\n",
       "      <td>-3.266925</td>\n",
       "      <td>-2.656432</td>\n",
       "      <td>-4.714286</td>\n",
       "      <td>1.220273</td>\n",
       "      <td>0.992239</td>\n",
       "      <td>0.567893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9094</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>251</td>\n",
       "      <td>6.605263</td>\n",
       "      <td>4</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>-3.048736</td>\n",
       "      <td>-3.037124</td>\n",
       "      <td>-3.328020</td>\n",
       "      <td>-3.067213</td>\n",
       "      <td>-6.285714</td>\n",
       "      <td>1.095780</td>\n",
       "      <td>1.009907</td>\n",
       "      <td>0.483179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9095</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>8</td>\n",
       "      <td>307</td>\n",
       "      <td>172</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>1113</td>\n",
       "      <td>6.470930</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>-2.619111</td>\n",
       "      <td>-2.704513</td>\n",
       "      <td>-3.311358</td>\n",
       "      <td>-2.652584</td>\n",
       "      <td>-5.714286</td>\n",
       "      <td>1.224382</td>\n",
       "      <td>0.980799</td>\n",
       "      <td>0.473290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9096</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>32</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>235</td>\n",
       "      <td>7.343750</td>\n",
       "      <td>3</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.057433</td>\n",
       "      <td>-3.052017</td>\n",
       "      <td>-3.333574</td>\n",
       "      <td>-3.074909</td>\n",
       "      <td>-6.428571</td>\n",
       "      <td>1.092253</td>\n",
       "      <td>1.007501</td>\n",
       "      <td>0.474758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9097</th>\n",
       "      <td>ESFP</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>21</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.151359</td>\n",
       "      <td>-3.128964</td>\n",
       "      <td>-3.339128</td>\n",
       "      <td>-3.177844</td>\n",
       "      <td>-6.571429</td>\n",
       "      <td>1.067167</td>\n",
       "      <td>1.015622</td>\n",
       "      <td>0.476147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9098 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  sentence_count  syll_count  word_count  word_per_sentence  \\\n",
       "0     INFJ              24         870         579          24.125000   \n",
       "1     ENTP              41        1700        1252          30.536585   \n",
       "2     INTP              42        1326         895          21.309524   \n",
       "3     INTJ              48        1699        1160          24.166667   \n",
       "4     ENTJ              42        1509        1035          24.642857   \n",
       "...    ...             ...         ...         ...                ...   \n",
       "9093  ENFP              15         332         183          12.200000   \n",
       "9094  ISTP               4          60          38           9.500000   \n",
       "9095  INFJ               8         307         172          21.500000   \n",
       "9096  ENTJ               3          55          32          10.666667   \n",
       "9097  ESFP               2           1           1           0.500000   \n",
       "\n",
       "      word_length  avg_word_length  count_unique_word       TTR  \\\n",
       "0            3154         5.447323                370  0.639033   \n",
       "1            6266         5.004792                607  0.484824   \n",
       "2            4879         5.451397                525  0.586592   \n",
       "3            6028         5.196552                591  0.509483   \n",
       "4            5539         5.351691                545  0.526570   \n",
       "...           ...              ...                ...       ...   \n",
       "9093         1105         6.038251                 15  0.081967   \n",
       "9094          251         6.605263                  4  0.105263   \n",
       "9095         1113         6.470930                  7  0.040698   \n",
       "9096          235         7.343750                  3  0.093750   \n",
       "9097           21        21.000000                  2  2.000000   \n",
       "\n",
       "      neg_sentiment  ...   disgust       joy  syll_count_scaled  \\\n",
       "0             0.075  ...  0.027972  0.139860          -1.639844   \n",
       "1             0.086  ...  0.031414  0.094241          -0.196164   \n",
       "2             0.080  ...  0.065990  0.116751          -0.846690   \n",
       "3             0.053  ...  0.046512  0.081395          -0.197903   \n",
       "4             0.127  ...  0.057778  0.102222          -0.528384   \n",
       "...             ...  ...       ...       ...                ...   \n",
       "9093          0.056  ...  0.000000  0.000000          -2.575627   \n",
       "9094          0.000  ...  0.000000  0.428571          -3.048736   \n",
       "9095          0.013  ...  0.034483  0.103448          -2.619111   \n",
       "9096          0.000  ...  0.200000  0.000000          -3.057433   \n",
       "9097          0.000  ...  0.000000  0.000000          -3.151359   \n",
       "\n",
       "      word_count_scaled  count_unique_word_scaled  word_length_scaled  \\\n",
       "0             -1.694270                 -1.295213           -1.670848   \n",
       "1             -0.023770                  0.021113           -0.173952   \n",
       "2             -0.909904                 -0.434325           -0.841110   \n",
       "3             -0.252130                 -0.067753           -0.288432   \n",
       "4             -0.562401                 -0.323243           -0.523645   \n",
       "...                 ...                       ...                 ...   \n",
       "9093          -2.677209                 -3.266925           -2.656432   \n",
       "9094          -3.037124                 -3.328020           -3.067213   \n",
       "9095          -2.704513                 -3.311358           -2.652584   \n",
       "9096          -3.052017                 -3.333574           -3.074909   \n",
       "9097          -3.128964                 -3.339128           -3.177844   \n",
       "\n",
       "      sentence_count_scaled  TTR_scaled  avg_word_length_scaled  \\\n",
       "0                 -3.428571    0.764467                0.986176   \n",
       "1                 -1.000000   -0.888211                7.318157   \n",
       "2                 -0.857143    0.477330                0.924393   \n",
       "3                  0.000000    0.268724                1.143983   \n",
       "4                 -0.857143    0.574755                0.931088   \n",
       "...                     ...         ...                     ...   \n",
       "9093              -4.714286    1.220273                0.992239   \n",
       "9094              -6.285714    1.095780                1.009907   \n",
       "9095              -5.714286    1.224382                0.980799   \n",
       "9096              -6.428571    1.092253                1.007501   \n",
       "9097              -6.571429    1.067167                1.015622   \n",
       "\n",
       "      word_per_sentence_scaled  \n",
       "0                     0.494162  \n",
       "1                     0.023770  \n",
       "2                     1.061555  \n",
       "3                         -inf  \n",
       "4                     0.656134  \n",
       "...                        ...  \n",
       "9093                  0.567893  \n",
       "9094                  0.483179  \n",
       "9095                  0.473290  \n",
       "9096                  0.474758  \n",
       "9097                  0.476147  \n",
       "\n",
       "[9098 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E - I personality model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8767, 8803, 8809, 8871, 8907, 8949, 8961, 9016, 9034, 9063, 9066]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.type.isnull() == True].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index = [8767, 8803, 8809, 8871, 8907, 8949, 8961, 9016, 9034, 9063, 9066],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df.replace([np.inf, -np.inf], np.nan,inplace = True)\n",
    "df.fillna(df.median(),inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for mbti in df['type']:\n",
    "    if 'I' in mbti:\n",
    "        ls.append(1)\n",
    "    else:\n",
    "        ls.append(0)\n",
    "df['E-I'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for mbti in df['type']:\n",
    "    if 'N' in mbti:\n",
    "        ls.append(1)\n",
    "    else:\n",
    "        ls.append(0)\n",
    "\n",
    "df['N-S'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for mbti in df['type']:\n",
    "    if 'T' in mbti:\n",
    "        ls.append(1)\n",
    "    else:\n",
    "        ls.append(0)\n",
    "\n",
    "df['T-F'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for mbti in df['type']:\n",
    "    if 'J' in mbti:\n",
    "        ls.append(1)\n",
    "    else:\n",
    "        ls.append(0)\n",
    "\n",
    "df['J-P'] = ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'sentence_count',\n",
       " 'syll_count',\n",
       " 'word_count',\n",
       " 'word_per_sentence',\n",
       " 'word_length',\n",
       " 'avg_word_length',\n",
       " 'count_unique_word',\n",
       " 'TTR',\n",
       " 'neg_sentiment',\n",
       " 'neu_sentiment',\n",
       " 'pos_sentiment',\n",
       " 'compound_sentiment',\n",
       " 'fear',\n",
       " 'anger',\n",
       " 'anticip',\n",
       " 'trust',\n",
       " 'surprise',\n",
       " 'positive',\n",
       " 'negative',\n",
       " 'sadness',\n",
       " 'disgust',\n",
       " 'joy',\n",
       " 'syll_count_scaled',\n",
       " 'word_count_scaled',\n",
       " 'count_unique_word_scaled',\n",
       " 'word_length_scaled',\n",
       " 'sentence_count_scaled',\n",
       " 'TTR_scaled',\n",
       " 'avg_word_length_scaled',\n",
       " 'word_per_sentence_scaled',\n",
       " 'E-I',\n",
       " 'N-S',\n",
       " 'T-F',\n",
       " 'J-P']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df.columns.tolist()\n",
    "len(cols)\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/ALL_feature_eng.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Froest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols[9:30]]\n",
    "y = df['E-I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7598093142647598"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "cls_IE = RandomForestClassifier(max_depth=None,n_estimators = 100,criterion='gini')\n",
    "cls_IE.fit(X_train, y_train)\n",
    "cls_IE.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-S label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols[9:30]]\n",
    "y = df['N-S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624862486248625"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "cls_NS = RandomForestClassifier(max_depth=None,n_estimators = 100,criterion='gini')\n",
    "cls_NS.fit(X_train, y_train)\n",
    "cls_NS.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-F label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols[9:30]]\n",
    "y = df['T-F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6696002933626696"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "cls_tf = RandomForestClassifier(max_depth=None,n_estimators = 100,criterion='gini')\n",
    "cls_tf.fit(X_train, y_train)\n",
    "cls_tf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### J-P label model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[cols[9:30]]\n",
    "y = df['J-P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5852585258525853"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "\n",
    "cls_jp = RandomForestClassifier(max_depth=None,n_estimators = 100,criterion='gini')\n",
    "cls_jp.fit(X_train, y_train)\n",
    "cls_jp.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(cls_IE, open('../notebooks/models/RF_IE_Model', 'wb'))\n",
    "pickle.dump(cls_IE, open('../notebooks/models/RF_NS_Model', 'wb'))\n",
    "pickle.dump(cls_IE, open('../notebooks/models/RF_TF_Model', 'wb'))\n",
    "pickle.dump(cls_IE, open('../notebooks/models/RF_JP_Model', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
